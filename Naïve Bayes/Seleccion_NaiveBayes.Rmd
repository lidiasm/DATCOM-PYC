---
title: "NaiveBayes"
author: "Laura Antequera Pérez"
date: "10/1/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preprocesamiento

Para este preprocesamiento nos vamos a encargar principalmente de eliminar las filas/instancias que contengan demasiados valores perdidos, balancear las clases para la etiqueta que sea necesario y especialmente haremos un estudio de selección de características. Aplicaremos el método de selección de características dos, una por cada etiqueta, por lo que obtendríamos dos conjuntos que están formados cada uno 
de ellos por las características que más influyen en cada etiqueta. A dichos conjuntos llegaremos ejecutando distintos métodos y considerando las que ganen por mayoría. 

```{r message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(mice)
library(caret)
library(purrr)
library(mice)
library(ROSE)
library(caret)
library(naivebayes)
library(GoodmanKruskal)
library(e1071)
library(ggplot2)
```

En primer lugar cargaremos los datos disponibles para entrenamiento y las etiquetas:
```{r}
df <- read.csv("training_set_features.csv")

glimpse(df)


label <- read.csv("training_set_labels.csv")
glimpse(label)
```

Cargamos tambien el conjunto de pruba o test:

```{r}
#Cargamos ctest
ctest <- read.csv("test_set_features.csv")
respondent_id <- ctest[,1]
ctest <- ctest[,-1]

#Las comillas vacías se consideran NA
ctest$education[ctest$education == ""] <- NA
ctest$income_poverty[ctest$income_poverty == ""] <- NA
ctest$marital_status[ctest$marital_status == ""] <- NA
ctest$rent_or_own[ctest$rent_or_own == ""] <- NA
ctest$employment_status[ctest$employment_status == ""] <- NA
ctest$employment_industry[ctest$employment_industry == ""] <- NA
ctest$employment_occupation[ctest$employment_occupation == ""] <- NA

glimpse(ctest)
ctest <-lapply(ctest[,1:35],as.factor)
ctest <- as.data.frame(ctest)
```



Indicamos que las comillas vacías de las variables tipo *char* son *missing values*:
```{r}
df$education[df$education == ""] <- NA
df$income_poverty[df$income_poverty == ""] <- NA
df$marital_status[df$marital_status == ""] <- NA
df$rent_or_own[df$rent_or_own == ""] <- NA
df$employment_status[df$employment_status == ""] <- NA
df$employment_industry[df$employment_industry == ""] <- NA
df$employment_occupation[df$employment_occupation == ""] <- NA

map_dbl(df, .f = function(x){sum(is.na(x))})
```

Unimos el conjunto de entrenamiento con el de sus etiquetas
```{r}
# train + label
joined_df = merge(df,label)
# Eliminamos la variable respondent_id
joined_df <- joined_df[,-1]
```

```{r}
joined_df <-lapply(joined_df[,1:37],as.factor)
joined_df <- as.data.frame(joined_df)
```



#Selección de características:

## Chi-cuadrado
En primer lugar, decidimos usar el test Chi-cuadrado para hacernos una idea de qué variables no son estadísticamente significativas con cada una de las etiquetas
```{r cars, message=FALSE, warning=FALSE}
chi1 <- lapply(joined_df[ ,1:35],
              FUN = chisq.test, # chi square test
              y = joined_df$h1n1_vaccine)
```
Podemos observar que variables como *household_children*, *census_msa*, *sex*, *behavioral_outside_home* o *behavioral_large_gatherings* no nos van a aportar información para clasificar la etiqueta *h1n1_vaccine*.

```{r cars}
chi2 <- lapply(joined_df[ ,1:35],
              FUN = chisq.test, # chi square test
              y = joined_df$seasonal_vaccine)
```
Para la clasificación de la vacuna *seasonal_vaccine* tenemos que las variables *census_msa*, *child_under_6_months* y *behavioral_antiviral_meds* son irrelevantes.


## Ganancia de información
Como vamos a realizar la clasificación siguiendo el método *Binary Relevance* vamos a separar el conjunto de entrenamiento para cada una de las etiquetas:
```{r}
train_seasonal <- joined_df[,-36]
train_h1n1 <- joined_df[,-37]
```

Estudiemos cuáles son los atributos o características que deberían salir de nuestro estudio pues no nos van a aportar información útil:

- Para h1n1_vaccine:
```{r}
pesosG <- FSelectorRcpp::information_gain(h1n1_vaccine ~ ., train_h1n1)
# Ordenamos y quedamos con los 10 mejores que visualizamos
visual <- head(pesosG %>% arrange(desc(importance)),35)
visual
```
Basándonos en la ganancia de información, seleccionamos las características o variables más importantes:
```{r}

train_h1n1_red <- train_h1n1[,c(10,17,16,20,15,11,19,34,35,14,1,2,18,12,6,36)]
```

Una vez que hemos seleccionado las características, estudiamos la independencia entre ellas pues sabemos que una de las limitaciones del clasificador de Naive-Bayes es la suposición de predictores totalmente independientes, lo cuál es muy difícil de lograr.
```{r}
GKmatrix1<- GKtauDataframe(train_h1n1_red)
plot(GKmatrix1, corrColors = "purple2")
```
Observemos que `doctor_recc_h1n1` y `doctor_recc_seas` alcanza una *tau=0.53* y *tau=0.49* así que decidiremos quedarnos con `doctor_recc_h1n1` pues con este conjunto clasificaremos la etiqueta `h1n1_vaccine`. Lo mismo ocurre con `employment_industry`, `employment_occupation` y `health_worker` pues las tres mantienen una asociación muy fuerte, decidimos quedarnos con `employment_industry` que engloba tanto a `health_worker` como a `employment_occupation`. En último lugar, observamos una asociación más débil, pero destacable, entre `opinion_h1n1_risk` - `opinion_seas_risk` y entre `opinion_h1n1_vac_effective` - `opinion_seas_vac_effective`. De estas últimas, decidimos quedarnos con las que hacen referencia a `h1n1_vaccine`. Mostramos las características que mantenemos:
```{r}
train_h1n1_red <- train_h1n1_red[,-c(7,4,6,8,11)]
colnames(train_h1n1_red)
```

- Para seasonal_vaccine:
```{r}
pesosG <- FSelectorRcpp::information_gain(seasonal_vaccine ~ ., train_seasonal, type = "infogain")
visual <- head(pesosG %>% arrange(desc(importance)),35)
visual
```
Seleccionamos las características más relevantes basándonos en la ganancia de información:
```{r}
train_seasonal_red <- train_seasonal[,c(19,20,11,22,34,12,15,1,29,33,2,9,28,36)]
```

```{r}
GKmatrix2<- GKtauDataframe(train_seasonal_red)
plot(GKmatrix2, corrColors = "purple2")
```
Decidimos quitar `employment_status` pues presenta una asociación fuerte con otras dos características:
```{r}
train_seasonal_red <- train_seasonal_red[,-9]
map_dbl(train_seasonal_red, .f = function(x){sum(is.na(x))})
```


## Relief Filter

El algoritmo encuentra pesos de atributos discretos basándose en una distancia entre instancias. La salida del algoritmo es un peso entre −1 y 1 para cada atributo, donde los pesos positivos mayores indican atributos más predictivos.

-Para h1n1_vaccine:
```{r}
library(FSelector)
weights <- relief(h1n1_vaccine~., train_h1n1, neighbours.count = 5, sample.size = 20)
print(weights)

weights %>% arrange(desc(attr_importance))
```
Las variables que se consideran más importantes para la vacuna h1n1 según el algoritmo `relief` son: *h1n1_knowledge*, *behavioral_antiviral_meds*, *behavioral_touch_face*, *opinion_h1n1_sick_from_vacc*, *opinion_h1n1_vacc_effective*, *opinion_h1n1_risk*, *employment_industry*, *chronic_med_condition*,  *household_adults*, *income_poverty* y *health_worker*. Como en el estudio anterior hemos visto que las variables de opinión y de recomendación del doctor (se repiten tanto para la vacuna h1n1 como para la seasonal) presentan una asociación fuerte hemos decidido no considerar ambas, por ejemplo de *opinion_seas_risk* y *opinion_h1n1_risk* nos quedamos solo con la que hace referencia a la vacuna h1n1 para que el clasificador *Naive_Bayes* solo trabaje con atributos independientes. 


Teniendo en cuenta los dos métodos anteriores seleccionaremos las que coinciden como más importantes para la vacuna h1n1:

```{r}
train_h1n1_red<-train_h1n1[,c(17,16,20,15,34,14,1,2,18,12,6,3,9,32,26,36)]
GKmatrix1<- GKtauDataframe(train_h1n1_red)
plot(GKmatrix1, corrColors = "purple2")
```
¡Cuidado con considerar *employment_industry* y *health_worker* que están correladas! Y en menor medida *behavioral_touch_face* y *behavioral_wash_hands*.
 
```{r}
weights1 <- relief(seasonal_vaccine~., train_seasonal, neighbours.count = 5, sample.size = 20)
print(weights1)

weights1 %>% arrange(desc(attr_importance))
```
Las variables que se consideran más importantes para la vacuna seasonal según el algoritmo `relief` son: *behavioral_avoidance*, *behavioral_outside_home*, *doctor_recc_seasonal*, *health_worker*, *opinion_seas_vacc_effective*, *opinion_seas_risk*, *race*, *hhs_geo_region*, *employment_occupation*

De nuevo, teniendo en cuenta los dos métodos anteriores seleccionaremos las que coinciden como más importantes para la vacuna seasonal:

```{r}
train_seasonal_red <- train_seasonal[,c(19,20,11,22,35,12,15,1,33,2,28,4,8,14,24,30,36)]
GKmatrix2<- GKtauDataframe(train_seasonal_red)
plot(GKmatrix2, corrColors = "purple2")
```
¡Cuidado con considerar *employment_occupation* y *health_worker* que están correladas!

## Método wrapper

Un método *wrapper* que se puede utilizar para la selección de características es *Eliminación de características recursivas* (RFE). Usamos la función `rfe ()` del paquete `caret`. Establecemos el parámetro `functions = nbFuncs` y  `functions = rfFuncs`. Realizaremos una validación cruzada de 5 folds.

```{r}
ctrl <- rfeControl(functions = rfFuncs, 
                       method = "cv", # k-fold CV
                       number = 5) # 5 = k folds

#Función que elimina aquellas instancias con un mínimo de NAs
delete.na <- function(DF, n=2) {
  DF[rowSums(is.na(DF)) <= n,]
}

#Eliminamos todas las filas que tengan algún NA
train_h1n1_red<-delete.na(train_h1n1_red,0)

rfe_mode_0 <- rfe(x = train_h1n1_red[ ,1:10], # predictor variables
               y = train_h1n1_red$h1n1_vaccine, # target variable
               sizes = 4:10, # minimum of 4 variables
               rfeControl = ctrl)
rfe_mode_0
```

```{r}
ctrl <- rfeControl(functions = nbFuncs, 
                       method = "cv", # k-fold CV
                       number = 5) # 5 = k folds

#Función que elimina aquellas instancias con un mínimo de NAs
delete.na <- function(DF, n=2) {
  DF[rowSums(is.na(DF)) <= n,]
}

#Eliminamos todas las filas que tengan algún NA
train_h1n1_red<-delete.na(train_h1n1_red,0)

rfe_mode <- rfe(x = train_h1n1_red[ ,1:10], # predictor variables
               y = train_h1n1_red$h1n1_vaccine, # target variable
               sizes = 4:10, # minimum of 4 variables
               rfeControl = ctrl)
rfe_mode
```
Para la vacuna h1n1, la salida de *RFE* nos proporciona como mejores las siguientes cinco variables predictoras:
*opinion_h1n1_risk, opinion_seas_risk, opinion_h1n1_vacc_effective, h1n1_knowledge, h1n1_concern* en el caso en el que el clasificador base sea *Naive-Bayes*. Si el clasificador base es *Random Forest* obtenemos también la variables que nos indican la opinión de los pacientes y *employment_industry* y *health_worker* que sabemos que no son independientes por el estudio previo en el que estudiabamos la correlación entre variables. 

```{r}
predictoras1 <- rfe_mode$optVariables
predictoras1
``` 
Eliminamos *employment_industry*
```{r}
predictoras1 <- predictoras1[-c(7,11)]

```



```{r}
ctrl <- rfeControl(functions = rfFuncs, 
                       method = "cv", # k-fold CV
                       number = 5) # 5 = k folds


#Eliminamos todas las filas que tengan algún NA
train_seasonal_red<-delete.na(train_seasonal_red,0)

rfe_mode_0 <- rfe(x = train_seasonal_red[ ,1:16], # predictor variables
               y = train_seasonal_red$seasonal_vaccine, # target variable
               sizes = 4:10, # minimum of 4 variables
               rfeControl = ctrl)
rfe_mode_0
```

```{r}
ctrl <- rfeControl(functions = nbFuncs,
                       method = "cv", # k-fold CV
                       number = 5) # 5 = k folds




rfe_mode <- rfe(x = train_seasonal_red[ ,1:12], # predictor variables
               y = train_seasonal_red$seasonal_vaccine, # target variable
               sizes = 4:10, # minimum of 4 variables
               rfeControl = ctrl)
rfe_mode
```

Para la vacuna seasonal, la salida de *RFE* nos proporciona como mejores las siguientes cinco variables predictoras:
*opinion_seas_risk, opinion_seas_vacc_effective, doctor_recc_seasonal, age_group, h1n1_concern*

```{r}
predictoras <- rfe_mode$optVariables
predictoras
``` 
Eliminamos *employment_occupation*
```{r}
predictoras1 <- predictoras1[-8]
```


# Clasificación

A continuación, para la clasificación con el algoritmo Naive-Bayes vamos a usar el método denominado **Binary Relenvance*, según el cuál entrenaremos tantos clasificadores como etiquetas distintas existan en los datos, es decir, dos. 

Consideramos únicamente las diez/once mejores características obtenidas con los métodos anteriores: 
```{r}
tra_h1n1<-train_h1n1[,c(predictoras1[1:10],"h1n1_vaccine")]
tra_seasonal<-train_seasonal[,c(predictoras[1:11],"seasonal_vaccine")]
test_h1n1 <- ctest[,predictoras1[1:10]]
test_seasonal <- ctest[,predictoras[1:11]]
```

```{r}
balanceado <- downSample(tra_h1n1, tra_h1n1$h1n1_vaccine)
dim(balanceado)
balanceado <- balanceado[,-12]
```

```{r}
control= trainControl(method="repeatedcv", number=10, repeats=2)

naive_bayes1 <- naiveBayes(balanceado, balanceado[,11], trControl = control, tuneLength = 7)
h1n1_vacc <- predict(naive_bayes1, newdata = test_h1n1, type = "raw")
naive_bayes2 <- naiveBayes(tra_seasonal, tra_seasonal[,12], trControl = control, tuneLength = 7)
seasonal_vacc <- predict(naive_bayes2, newdata = test_seasonal, type = "raw")

submission44 <- data.frame(respondent_id, h1n1_vacc[,2],seasonal_vacc[,2])
colnames(submission44) <-c('respondent_id', 'h1n1_vaccine', 'seasonal_vaccine')

write.csv(submission44,"C:/Users/iemat/Desktop/Preprocesamiento/Preprocesamiento/submission44.csv", row.names = FALSE)
```
 
En la competición hemos obtenido un $0.79$ aproximadamente. Para ver si mejora vamos a ejecutar un ensemble en el que se seleccionen aleatoriamente las características. Para ello, vamos e eliminar las que no sean independientes y no sean estadísticamente significativas con cada una de las etiquetas. En primer lugar, eliminaremos los atributos irrelevantes según el test *chi-cuadrado*:

- Eliminamos *household_children*, *census_msa*, *sex*, *behavioral_outside_home* o *behavioral_large_gatherings* en el caso de h1n1 y *behavioral_antiviral_meds*, *census_msa* y *child_under_6_months* en el caso de la vacuna seasonal. También eliminamos las variables que expresan la misma información para cada vacuna:
```{r}
tra_h1n1 <- train_h1n1[,-c(11,19,20,21,33,31,25,7,8,35)]
tra_seas <- train_seasonal[,-c(3,10,13,16,17,18,31,35)]
```
 
- Eliminamos los atributos no independientes o con una asociación fuerte según la medida de Kruskal y Goodman:

```{r}
GKmatrix1<- GKtauDataframe(tra_h1n1[,c(3,4,5,6,7,26)])
plot(GKmatrix1, corrColors = "purple2")
GKmatrix2<- GKtauDataframe(tra_seas[,c(3,4,5,6,7,28)])
plot(GKmatrix2, corrColors = "purple2")
```
Para h1n1 eliminamos *behavioral_touch_face*, *behavioral_antiviral_meds*, *behavioral_face_mask*.
Para seasonal eliminamos *bahavioral_avoidance*, *behavioral_large_gatherings* y *behavioral_outside_home* y *behavioral_face_mask*.

```{r}
tra_h1n1 <- train_h1n1[,-c(3,5,9,11,19,20,21,33,31,25,7,8,35)]
tra_seas <- train_seasonal[,-c(3,4,5,7,8,10,13,16,17,18,31,35)]
```

```{r}
GKmatrix1<- GKtauDataframe(tra_h1n1)
plot(GKmatrix1, corrColors = "purple2")
```

```{r}
GKmatrix2<- GKtauDataframe(tra_seas)
plot(GKmatrix2, corrColors = "purple2")
```

Realizamos diferentes pruebas manualmente, eliminando las variables que dan lugar a algún tipo de dependencia entre ellas.
```{r}
tra_h1n1 <- train_h1n1[,-c(3,5,9,11,13,19,20,21,33,31,25,26,27,28,29,7,8,34,35)]
tra_seas <- train_seasonal[,-c(3,4,5,7,8,10,13,16,17,18,31,26,27,28,29,7,8,34,35)]
```


Procedemos a la clasificación con el uso del ensemble. Decidimos seleccionar en cada iteración $10$ atributos y entrenaremos un total de 100 modelos con el algoritmo de Naive-Bayes:

```{r}
test_seas <-ctest[,-c(3,4,5,7,8,10,13,16,17,18,31,26,27,28,29,7,8,34,35)]
mat_val_seasonal= c()
for(i in 1:100){
    val_ale = sample(18,12,replace=FALSE)
    model_seasonal <- train(tra_seas[,c(val_ale)],tra_seas[,19],'nb',trControl=trainControl(method='cv',number=10),tuneLength = 10)
    seasonal_predict = model_seasonal %>% predict(test_seas)
    mat_val_seasonal = cbind(mat_val_seasonal,as.numeric(as.character(seasonal_predict)))
}
```

Antes de ejecutar el clasificador para h1n1, aplicamos la técnica *downsampling* para balancear sus clases
```{r}
train_h1n1_balanced <- downSample(tra_h1n1,tra_h1n1$h1n1_vaccine)
dim(train_h1n1_balanced)
train_h1n1_balanced <- train_h1n1_balanced[,-18]
```

```{r}
test_h1 <- ctest[,-c(3,5,9,11,13,19,20,21,33,31,25,26,27,28,29,7,8,34,35)]
mat_val_h1n1 = c()
for(i in 1:100){
    val_ale = sample(16,12,replace=FALSE)
    model_h1n1 <- train(train_h1n1_balanced[,c(val_ale)], train_h1n1_balanced[,17],'nb',
                        trControl = trainControl("cv", number = 10),tuneLength = 10)
    h1n1_predict = model_h1n1 %>% predict(test_h1)
    mat_val_h1n1 = cbind(mat_val_h1n1,as.numeric(as.character(h1n1_predict)))
}
```



```{r}
seasonal_vacc <- apply(mat_val_seasonal,1,mean)
h1n1_vacc <- apply(mat_val_h1n1,1,mean)
submission44 <- data.frame(respondent_id, h1n1_vacc,seasonal_vacc)
colnames(submission44) <-c('respondent_id', 'h1n1_vaccine', 'seasonal_vaccine')
write.csv(submission44,"C:/Users/iemat/Desktop/Preprocesamiento/Preprocesamiento/submission44.csv", row.names = FALSE)
```

