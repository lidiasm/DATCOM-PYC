---
title: "Preprocesamiento7"
author: "Laura Antequera Pérez"
date: "5/1/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preprocesamiento

En este preprocesamiento nos centraremos en crear un conjunto de entrenamiento para cada una de las dos etiquetas que tenemos. Para ello,  eliminaremos posible ruido, eliminaremos filas que superen un determinado número de valores perdidos, imputaremos dichos valores perdidos usando el modelo logístico multinomial, seleccionaremos las características más relevantes y balancearemos si es necesario.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(mice)
library(caret)
library(purrr)
library(mice)
library(ROSE)
library(caret)
library(naivebayes)
library(GoodmanKruskal)
library(e1071)
library(ggplot2)
library(FSelectorRcpp)
```

En primer lugar cargaremos los datos disponibles para entrenamiento y las etiquetas correspondientes:
```{r}
df <- read.csv("training_set_features.csv")

glimpse(df)


label <- read.csv("training_set_labels.csv")
glimpse(label)
```


Indicamos que las comillas vacías son *missing values*:
```{r}
df$education[df$education == ""] <- NA
df$income_poverty[df$income_poverty == ""] <- NA
df$marital_status[df$marital_status == ""] <- NA
df$rent_or_own[df$rent_or_own == ""] <- NA
df$employment_status[df$employment_status == ""] <- NA
df$employment_industry[df$employment_industry == ""] <- NA
df$employment_occupation[df$employment_occupation == ""] <- NA

map_dbl(df, .f = function(x){sum(is.na(x))})
```

```{r}
# train + label
joined_df = merge(df,label)
# Eliminamos la variable respondent_id
joined_df <- joined_df[,-1]
```

```{r}
joined_df <-lapply(joined_df[,1:37],as.factor)
joined_df <- as.data.frame(joined_df)
```

Vamos a estudiar el comportamiento de los atributos en relación con cada una de las dos etiquetas. Vamos a aplicar un paquete específico, `FSelectorCp` para estudiar cuáles son las variables predictivas que explican mejor a cada etiqueta. 


**Con la etiqueta h1n1_vaccine**:
```{r}
pesosG <- FSelectorRcpp::information_gain(h1n1_vaccine ~ ., joined_df[,-37])
# Ordenamos y quedamos con los 10 mejores que visualizamos
visual <- head(pesosG %>% arrange(desc(importance)), 10)
ggplot(data=visual, aes(x=reorder(attributes, -importance), y=importance)) +
geom_bar(fill="cornflowerblue", stat="identity")
```
```{r}
mejores_7 <- FSelectorRcpp::cut_attrs(pesosG, k=7)
mejores_7
```
La detección de ruido resulta esencial para algunos algoritmos muy sensibles. Veremos un ejemplo de aplicación con un algoritmo muy
característico: **Iterative Partitioning Filter** implementado en el paquete `NoiseFiltersR`. Se basa en identificar instancias en los que los valores de alguna(s) variable(s) no se corresponde con lo esperado.Se construye un clasificador base en cada una de las `nfolds`particiones de `data`. Luego, se prueban en todo el conjunto de datos y la eliminación de instancias ruidosas se decide mediante esquemas de votación por consenso o por mayoría. Finalmente, una proporción de buenas instancias (es decir, aquellas cuya etiqueta concuerda con todos los clasificadores base) se almacena y se elimina para la siguiente iteración. El proceso se detiene después de siteraciones en las que no se han peliminado suficientes instancias ruidosas (según la proporción ). En esta implementación, el clasificador base utilizado es C4.5.

```{r}
library(NoiseFiltersR)
set.seed(1)
resultado <- NoiseFiltersR::IPF(h1n1_vaccine ~ ., data=joined_df[,-37], s=2)
```

Nos quedamos con el dataset limpio de ruido, observemos sus dimensiones y los *missing values* por cada atributo:
```{r}
train <- resultado$cleanData
dim(train)
map_dbl(train, .f = function(x){sum(is.na(x))})
```

Vamos a seleccionar las $7$ variables que dijimos que eran más importantes: 
```{r}
train_h1n1 <- train[,c(10,11,15,16,17,19,20,36)]
map_dbl(train_h1n1, .f = function(x){sum(is.na(x))})
```

A continuación, vamos a usar el modelo logístico multinomial para imputar los NA pues tenemos factores con dos o más niveles
```{r}
imputed_Data = mice(train_h1n1, m=5, maxit = 5, method = 'polyreg', seed = 500)
data <- complete(imputed_Data)

map_dbl(data, .f = function(x){sum(is.na(x))})
```

Como las clases están desbalanceadas tendremos que aplicar alguna técnica para corregir este problema
```{r}
prop.table(table(data$h1n1_vaccine))
table(data$h1n1_vaccine)
```

Vamos a balancear dicha etiqueta:

```{r}
data_balanc_h1n1 <-downSample(data,data$h1n1_vaccine)
data_balanc_h1n1 %>%group_by(h1n1_vaccine) %>% summarise(total=n())

data_balanc_h1n1 <-data_balanc_h1n1[,-9]
glimpse(data_balanc_h1n1)
```

**Con la etiqueta seasonal_vaccine**:
```{r}
pesosG <- FSelectorRcpp::information_gain(seasonal_vaccine ~ ., joined_df[,-36])
# Ordenamos y quedamos con los 10 mejores que visualizamos
visual <- head(pesosG %>% arrange(desc(importance)), 10)
ggplot(data=visual, aes(x=reorder(attributes, -importance), y=importance)) +
geom_bar(fill="cornflowerblue", stat="identity")
```
```{r}
mejores_7 <- FSelectorRcpp::cut_attrs(pesosG, k=7)
mejores_7
```

Detección de ruido:
```{r}
set.seed(1)
resultado <- NoiseFiltersR::IPF(seasonal_vaccine ~ ., data=joined_df[,-36], s=2)
```

```{r}
train <- resultado$cleanData
dim(train)
map_dbl(train, .f = function(x){sum(is.na(x))})
```
Decidimos quedarnos con filas que solo tengan un valor perdido como máximo. De esta forma nos hemos quedado con $10927$ instancias para entrenar y hemos bajado considerablemente el porcentaje de valores perdidos para el atributo `employment_industry` (era un atributo preocupante pues tiene 21 niveles o categorías lo cuál haría complicada la imputación.
```{r}
delete.na <- function(DF, n=1) {
  DF[rowSums(is.na(DF)) <= n,]
}

t <- delete.na(train)

map_dbl(t, .f = function(x){sum(is.na(x))})
dim(t)
```

No vamos a realizar balanceo para esta etiqueta:
```{r}
table(t$seasonal_vaccine)
prop.table(table(t$seasonal_vaccine))
```
Vamos a seleccionar las $7$ variables que dijimos que eran más importantes: "opinion_seas_vacc_effective", "opinion_seas_risk"           "doctor_recc_seasonal", "age_group", "opinion_h1n1_risk", "opinion_h1n1_vacc_effective" y "employment_industry" 
```{r}
train_seasonal <- t[,c(11,16,17,19,20,22,34,36)]
map_dbl(train_seasonal, .f = function(x){sum(is.na(x))})
```
Imputación:
```{r}
imputed_Data = mice(train_seasonal, m=5, maxit = 5, method = 'polyreg', seed = 500)
train_seasonal_c <- complete(imputed_Data)

map_dbl(train_seasonal_c, .f = function(x){sum(is.na(x))}) 
```

A continuación cargamos los datos de test

```{r}
#Cargamos test
test <- read.csv("test_set_features.csv")
respondent_id <- test[,1]
test <- test[,-1]

test$education[test$education == ""] <- NA
test$income_poverty[test$income_poverty == ""] <- NA
test$marital_status[test$marital_status == ""] <- NA
test$rent_or_own[test$rent_or_own == ""] <- NA
test$employment_status[test$employment_status == ""] <- NA
test$employment_industry[test$employment_industry == ""] <- NA
test$employment_occupation[test$employment_occupation == ""] <- NA

glimpse(test)
test <-lapply(test[,1:35],as.factor)
test <- as.data.frame(test)
```

Imputamos los valores perdidos de test:
```{r}
test_h1n1 <- test[,c(10,11,15,16,17,19,20)]
imputed_Data = mice(test_h1n1, m=5, maxit = 5, method = 'polyreg', seed = 500)
test_cleanh1n1 <- complete(imputed_Data)

map_dbl(test_cleanh1n1, .f = function(x){sum(is.na(x))})

```

```{r}
test_seasonal<- test[,c(11,16,17,19,20,22,34)]
imputed_Data = mice(test_seasonal, m=5, maxit = 5, method = 'polyreg', seed = 500)
test_cleanseasonal<- complete(imputed_Data)

map_dbl(test_cleanseasonal, .f = function(x){sum(is.na(x))})

```
Procedemos a entrenar el clasificador en cada etiqueta.

# Clasificación

```{r}
train_control <- trainControl(
  method = "cv", 
  number = 10,
  verboseIter = TRUE,
  classProbs=TRUE,
  summaryFunction = twoClassSummary
  )
nb_grid <-   expand.grid(usekernel = c(TRUE, FALSE),
                         laplace = c(0, 1, 2, 3), 
                         adjust = c(0.75, 1, 1.25, 1.5))
#Para usar la metrica ROC necesitamos darle nombre a los level de factor
data_balanc_h1n1$h1n1_vaccine <- make.names(data_balanc_h1n1$h1n1_vaccine)
data_balanc_h1n1$h1n1_vaccine <- factor(data_balanc_h1n1$h1n1_vaccine)

train_seasonal$seasonal_vaccine <- make.names(train_seasonal$seasonal_vaccine)
train_seasonal$seasonal_vaccine <- factor(train_seasonal$seasonal_vaccine)

naive_bayes1 <- train(h1n1_vaccine ~ ., 
                               data = data_balanc_h1n1, 
                               method = "naive_bayes", 
                               tuneGrid = nb_grid,
                               metric="ROC",
                               trControl = train_control)

h1n1_vacc <- predict(naive_bayes1, newdata = test_cleanh1n1, type = "prob")

naive_bayes2 <- train(seasonal_vaccine ~ ., 
                               data = train_seasonal_c, 
                               method = "naive_bayes", 
                               tuneGrid = nb_grid,
                               metric="ROC",
                               trControl = train_control)

seasonal_vacc <- predict(naive_bayes2, newdata = test_cleanseasonal, type = "prob")

submission22 <- data.frame(respondent_id, h1n1_vacc[,2],seasonal_vacc[,2])
colnames(submission22) <-c('respondent_id', 'h1n1_vaccine', 'seasonal_vaccine')

write.csv(submission22,"C:/Users/iemat/Desktop/Preprocesamiento/Preprocesamiento/submission22.csv", row.names = FALSE)
```

```{r}
# Filtramos las probabilidades>0.5 para ponerse la vacuna h1n1 para ver la proporción
h1n1_vacc %>% filter(h1n1_vacc[,2]>0.5)
```

```{r}
seasonal_vacc %>% filter(seasonal_vacc[,2]>0.5)
```


```{r}
naive_bayes1 <- naiveBayes(data_balanc_h1n1, data_balanc_h1n1[,8])

naive_bayes2 <- naiveBayes(train_seasonal_c, train_seasonal_c[,8])

h1n1_vacc <- predict(naive_bayes1, newdata = test_h1n1, type = "raw")
seasonal_vacc <- predict(naive_bayes2, newdata = test_seasonal, type = "raw")
submission23 <- data.frame(respondent_id, h1n1_vacc[,2],seasonal_vacc[,2])
colnames(submission23) <-c('respondent_id', 'h1n1_vaccine', 'seasonal_vaccine')

write.csv(submission23,"C:/Users/iemat/Desktop/Preprocesamiento/Preprocesamiento/submission23.csv", row.names = FALSE)
```


Hemos obtenido un score por debajo de $0.8$, concluimos que la imputación de valores perdidos no nos aporta mejoría.


